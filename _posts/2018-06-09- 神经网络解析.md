---
layout: post
title: 神经网络解析
date: 2018-06-08
categories: 深度学习
tags: [神经网络]
---

> 摘要：通过对逻辑回归模型的研究，理解激励函数，损失函数，梯度下降等概念。

# 一 简介

神经网络是一种对人脑的仿生学实现，目前在某些领域已经有了较好的模拟，但还远远不够。目前随着技术在软件（各种深度学习框架和生态）以及硬件（GPU）上的计算能力的突破，人工智能得以有可能以较低的成本去替代掉较高的人工成本，今年大热起来。

神经网络目前主要应用在图像（密集型矩阵），语音（密集型矩阵）和文本（稀疏型矩阵）分类识别。

# 二 基本概念和原理

## 2.1 网络结构

![网络结构](http://blog.luojia.ren/images/神经网络/网络结构.png)

![神经元](http://blog.luojia.ren/images/神经网络/神经元.png)

## 2.2 逻辑回归

逻辑回归是一种最简化的网络结构。

![逻辑回归](http://blog.luojia.ren/images/神经网络/逻辑回归.png)

## 2.3 激励函数

主要作用提供规模化的非线性能力，模拟的是神经元的被激发的概念。

### 常用的激励函数

函数| Sigmoid | tanh | ReLu（普遍率最高）
--- | ---| ---| ---
形状 | ![Sigmoid](http://blog.luojia.ren/images/神经网络/sigmoid.png) | ![Sigmoid](http://blog.luojia.ren/images/神经网络/tanh.png) | ![Sigmoid](http://blog.luojia.ren/images/神经网络/relu.png)
优点 | 在任何区间都是可导的| 中心对称；任何区间可导 | 学习的效率高
缺点 | 不是中心对称；当值趋向较大或者较小的时候，学习的效率很低 | 当值趋向较大或者较小的时候，学习的效率很低 | 在小于 0 的区间段会有点问题
情景推荐 | | |

## 2.4 损失函数

用来评价学习出来的输出和我们预期的输出之间的差距。

### 常用损失函数

1. 0-1 损失函数：如果预测值和真实值一样，损失值就为 0；如果不一样，损失值就为1
2. 绝对值损失函数：利用两个数的差的绝对值作为衡量预测值和真实值之间的差
3. 均方误差损失函数：计算模型输出与真实输出的差的平方，再把 n 个样本的差平方加起来，然后求平均，得到均方差

## 2.5 梯度下降

通过一种渐进性的形式来调整我们整个函数的形态，目的是让损失函数趋近于全局最小值。


## 2.6 反向传播

通过每一次的训练结果逆向来调节每一层的每一个神经元的 w 和 b 的值来达到全局损失最小。

## 2.7 训练过程理解

> 传播按层进行，中间没有交叉，所有层全部算好后再一次性更新参数

![训练过程](http://blog.luojia.ren/images/神经网络/训练过程.png)